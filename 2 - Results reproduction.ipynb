{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7711086d",
   "metadata": {},
   "source": [
    "# Legal document classification in zero-shot cross lingual transfer setting\n",
    "\n",
    "# Part II: Results reproduction\n",
    "\n",
    "Date: May 2025\n",
    "\n",
    "Project of course: Natural Language Processing - ENSAE 3A S2\n",
    "\n",
    "Author: Noémie Guibé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532a2ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 01:49:03.325097: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-03 01:49:03.326106: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 01:49:03.333318: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 01:49:03.430722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746236943.538909  116523 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746236943.612872  116523 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746236943.717755  116523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746236943.717802  116523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746236943.717806  116523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746236943.717809  116523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 01:49:03.727475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import pandas as pd \n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39096caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data base\n",
    "df = pd.read_parquet('https://minio.lab.sspcloud.fr/nguibe/NLP/multi_eurlex_reduced.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192611c4",
   "metadata": {},
   "source": [
    "# 1 - First result reproduction: Performance drop from English-only fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d729c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define R-Precision computation\n",
    "def r_precision(y_true, y_pred, top_k=10):\n",
    "    \"\"\"\n",
    "    R-Precision: Precision at top-k (where k is the number of relevant labels).\n",
    "    \"\"\"\n",
    "    precision_list = []\n",
    "    for i in range(len(y_true)):\n",
    "        true_labels = y_true[i]\n",
    "        predicted_scores = y_pred[i]\n",
    "        \n",
    "        # Get the indices of top-k predicted labels based on predicted scores\n",
    "        top_k_indices = predicted_scores.argsort()[-top_k:][::-1]\n",
    "        \n",
    "        # Calculate the number of relevant labels in the top-k predictions\n",
    "        relevant_in_top_k = sum([1 for idx in top_k_indices if true_labels[idx] == 1])\n",
    "        precision = relevant_in_top_k / top_k\n",
    "        precision_list.append(precision)\n",
    "    \n",
    "    return np.mean(precision_list)\n",
    "\n",
    "# Add additional metrics (Micro, Macro F1)\n",
    "def evaluate_model(model, test_dataset, batch_size=batch_size):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for batch in test_dataset.batch(batch_size):\n",
    "        #input_ids = batch['input_ids']\n",
    "        #attention_mask = batch['attention_mask']\n",
    "        #(input_ids, attention_mask), labels = batch\n",
    "        #labels = batch['labels']\n",
    "        inputs, labels = batch\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        # Get model predictions\n",
    "        logits = model(input_ids, attention_mask=attention_mask)[0]  # Directly access the first element\n",
    "        predictions = tf.sigmoid(logits).numpy()  # Apply sigmoid to get probabilities\n",
    "        #logits = model(input_ids, attention_mask=attention_mask)[0]\n",
    "        #predictions = tf.sigmoid(logits.logits).numpy()\n",
    "        \n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predictions)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate R-Precision\n",
    "    r_precision_score = r_precision(y_true, y_pred)\n",
    "    \n",
    "    # Calculate Micro and Macro F1 Scores\n",
    "    micro_f1 = f1_score(y_true, (y_pred > 0.5), average='micro',zero_division=0)\n",
    "    macro_f1 = f1_score(y_true, (y_pred > 0.5), average='macro',zero_division=0)\n",
    "    \n",
    "    # Calculate Label Ranking Average Precision (LRAP)\n",
    "    lrap_score = label_ranking_average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    # Log the results\n",
    "    print(f\"R-Precision: {r_precision_score:.4f}\")\n",
    "    print(f\"Micro F1: {micro_f1:.4f}\")\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "    print(f\"LRAP: {lrap_score:.4f}\")\n",
    "    \n",
    "    # Calculate evaluation time\n",
    "    evaluation_time = time.time() - start_time\n",
    "    print(f\"Evaluation time: {evaluation_time:.2f} seconds\")\n",
    "    \n",
    "    return r_precision_score, micro_f1, macro_f1, lrap_score, evaluation_time\n",
    "\n",
    "# Function to track training time and memory usage\n",
    "def track_training_time_and_memory(model, train_dataset, batch_size=batch_size, epochs=epochs):\n",
    "    # Track training time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use psutil to track memory usage\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    # Get initial memory usage\n",
    "    initial_memory = process.memory_info().rss / 1024 ** 2  # in MB\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_dataset.batch(batch_size), epochs=epochs)\n",
    "    \n",
    "    # Get final memory usage\n",
    "    final_memory = process.memory_info().rss / 1024 ** 2  # in MB\n",
    "    \n",
    "    # Track training time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"Initial memory usage: {initial_memory:.2f} MB\")\n",
    "    print(f\"Final memory usage: {final_memory:.2f} MB\")\n",
    "    print(f\"Memory used during training: {final_memory - initial_memory:.2f} MB\")\n",
    "    \n",
    "    return training_time, initial_memory, final_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77c2621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_runner/train_and_evaluate.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, label_ranking_average_precision_score\n",
    "from datasets import Dataset\n",
    "\n",
    "def run_training_pipeline(data, train_sample_size=1000, test_sample_size=5000, batch_size=8, epochs=2):\n",
    "    df = data.copy()\n",
    "\n",
    "    # Preprocess training and test sets\n",
    "    df['level_1_labels'] = df['eurovoc_concepts'].apply(lambda d: d.get('level_1', []))\n",
    "    train_df = df[df['split'] == 'train']\n",
    "    train_df['text'] = train_df['text'].apply(lambda x: x.get(\"en\") if isinstance(x, dict) else \"\")\n",
    "    test_df = df[df['split'] == 'test']\n",
    "\n",
    "    test_langs = [\"en\", \"fr\", \"de\", \"pl\", \"fi\"]\n",
    "    test_dfs = []\n",
    "    for lang in test_langs:\n",
    "        df_lang = test_df[test_df['text'].apply(lambda x: isinstance(x, dict) and lang in x)].copy()\n",
    "        df_lang['text'] = df_lang['text'].apply(lambda x: x[lang])\n",
    "        df_lang['lang'] = lang\n",
    "        test_dfs.append(df_lang)\n",
    "\n",
    "    final_test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "\n",
    "    train_df = train_df.sample(train_sample_size, random_state=42)\n",
    "    final_test_df = final_test_df.sample(test_sample_size, random_state=42)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(df[\"level_1_labels\"])\n",
    "    train_df[\"label_vector\"] = list(mlb.transform(train_df[\"level_1_labels\"]))\n",
    "    final_test_df[\"label_vector\"] = list(mlb.transform(final_test_df[\"level_1_labels\"]))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "    def tokenize(batch): \n",
    "        encodings = tokenizer(batch['text'], padding='max_length', truncation=True, max_length=512)\n",
    "        encodings['labels'] = batch['label_vector']\n",
    "        return encodings\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label_vector\"]]).map(tokenize, batched=True)\n",
    "    test_datasets = {\n",
    "        lang: Dataset.from_pandas(df[[\"text\", \"label_vector\"]]).map(tokenize, batched=True)\n",
    "        for lang, df in final_test_df.groupby(\"lang\")\n",
    "    }\n",
    "\n",
    "    def dataset_to_tf(dataset):\n",
    "        def gen():\n",
    "            for ex in dataset:\n",
    "                yield {\"input_ids\": ex[\"input_ids\"], \"attention_mask\": ex[\"attention_mask\"]}, ex[\"labels\"]\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_signature=(\n",
    "                {\n",
    "                    \"input_ids\": tf.TensorSpec(shape=(512,), dtype=tf.int64),\n",
    "                    \"attention_mask\": tf.TensorSpec(shape=(512,), dtype=tf.int64),\n",
    "                },\n",
    "                tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    train_tf = dataset_to_tf(train_dataset)\n",
    "    test_tf = {lang: dataset_to_tf(ds) for lang, ds in test_datasets.items()}\n",
    "\n",
    "    num_labels = len(mlb.classes_)\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "        'xlm-roberta-base',\n",
    "        num_labels=num_labels,\n",
    "        problem_type='multi_label_classification'\n",
    "    )\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "    # Train and evaluate with reusable functions\n",
    "    training_time, initial_memory, final_memory = track_training_time_and_memory(\n",
    "        model, train_tf, batch_size=batch_size, epochs=epochs\n",
    "    )\n",
    "\n",
    "    # Evaluate on all test languages using existing evaluate_model()\n",
    "    results = {}\n",
    "    for lang, lang_dataset in test_tf.items():\n",
    "        print(f\"[INFO] Evaluating on language: {lang}\")\n",
    "        r_prec, micro_f1, macro_f1, lrap, eval_time = evaluate_model(\n",
    "        model, lang_dataset, batch_size=batch_size\n",
    "        )\n",
    "        results[lang] = {\n",
    "        \"R-Precision\": r_prec,\n",
    "        \"Micro F1\": micro_f1,\n",
    "        \"Macro F1\": macro_f1,\n",
    "        \"LRAP\": lrap,\n",
    "        \"Eval Time (s)\": eval_time\n",
    "    }\n",
    "\n",
    "    # Optionally return training stats\n",
    "    results[\"training\"] = {\n",
    "    \"Training Time (s)\": training_time,\n",
    "    \"Initial Memory (MB)\": initial_memory,\n",
    "    \"Final Memory (MB)\": final_memory,\n",
    "    \"Memory Used (MB)\": final_memory - initial_memory\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748acb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116523/1555392674.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['text'] = train_df['text'].apply(lambda x: x.get(\"en\") if isinstance(x, dict) else \"\")\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 49.62 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 10.76 examples/s]\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00, 21.12 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 127.60 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00,  7.45 examples/s]\n",
      "All PyTorch model weights were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFXLMRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Choose your parameters\n",
    "train_size = 10\n",
    "test_size = 5\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "# Run training and evaluation\n",
    "results = run_training_pipeline(data=df,train_sample_size=train_size,\n",
    "                                test_sample_size=test_size,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs)\n",
    "\n",
    "# Display results\n",
    "import pprint\n",
    "pprint.pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
