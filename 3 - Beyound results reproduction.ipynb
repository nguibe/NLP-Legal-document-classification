{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f94e9b0",
   "metadata": {},
   "source": [
    "# Legal document classification in zero-shot cross lingual transfer setting\n",
    "\n",
    "# Part III: Performance improvement and pattern analysis\n",
    "\n",
    "Date: May 2025\n",
    "\n",
    "Project of course: Natural Language Processing - ENSAE 3A S2\n",
    "\n",
    "Author: Noémie Guibé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed2c5f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# import \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict, Counter\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11157383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "      --------------------------------------- 0.2/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.3/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.6/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.7/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.7/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.9/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.2/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.0/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.1/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.4/12.8 MB 3.4 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.7/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.9/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.1/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.3/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.6/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.9/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.8/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.4/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.7/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.6/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.6/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.1 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/16.3 MB 991.0 kB/s eta 0:00:17\n",
      "     ---------------------------------------- 0.1/16.3 MB 1.1 MB/s eta 0:00:15\n",
      "      --------------------------------------- 0.2/16.3 MB 1.7 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.5/16.3 MB 2.2 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.6/16.3 MB 2.4 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.8/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/16.3 MB 1.8 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.8/16.3 MB 1.8 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.3/16.3 MB 2.3 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.7/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.9/16.3 MB 2.8 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 2.1/16.3 MB 3.0 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 2.2/16.3 MB 3.0 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.5/16.3 MB 3.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.1/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.3/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.6/16.3 MB 3.7 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.9/16.3 MB 3.8 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 4.0/16.3 MB 3.8 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 4.0/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 4.1/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 4.4/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 4.6/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 4.8/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.9/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 5.2/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 5.4/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 5.6/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.7/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.9/16.3 MB 3.5 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 6.0/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 6.4/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 6.7/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 7.0/16.3 MB 3.7 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 7.3/16.3 MB 3.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 7.6/16.3 MB 3.8 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 7.9/16.3 MB 3.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 8.2/16.3 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 8.4/16.3 MB 3.9 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 8.8/16.3 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 9.1/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 9.3/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 9.5/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 9.7/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 10.0/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 10.3/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 10.4/16.3 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 10.7/16.3 MB 4.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 11.0/16.3 MB 4.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 11.2/16.3 MB 4.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 11.5/16.3 MB 4.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 11.7/16.3 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 12.1/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 12.5/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 12.6/16.3 MB 4.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 13.0/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 13.3/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 13.6/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 13.9/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 14.2/16.3 MB 4.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 14.5/16.3 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 14.8/16.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 15.1/16.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 15.4/16.3 MB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.7/16.3 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.0/16.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 16.3/16.3 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting de-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "     ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/14.6 MB 3.2 MB/s eta 0:00:05\n",
      "     ---------------------------------------- 0.2/14.6 MB 2.0 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.3/14.6 MB 1.7 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.4/14.6 MB 1.9 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.5/14.6 MB 1.8 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.6/14.6 MB 1.8 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.7/14.6 MB 1.9 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.8/14.6 MB 2.1 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 1.0/14.6 MB 2.2 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.1/14.6 MB 2.3 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.6/14.6 MB 2.0 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 2.1/14.6 MB 2.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.3/14.6 MB 2.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.5/14.6 MB 2.7 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.9/14.6 MB 2.8 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 3.1/14.6 MB 2.9 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.2/14.6 MB 2.9 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.6/14.6 MB 3.0 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.9/14.6 MB 3.1 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 4.2/14.6 MB 3.2 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.6/14.6 MB 3.3 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.8/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 5.0/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.3/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.7/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.9/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 6.0/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 6.4/14.6 MB 3.7 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 6.4/14.6 MB 3.7 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 6.5/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.8/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 7.0/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 7.3/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 7.5/14.6 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.8/14.6 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 8.0/14.6 MB 3.7 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 8.3/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.5/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.7/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 8.9/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.2/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.4/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 9.6/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 9.8/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 10.1/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 10.4/14.6 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 10.7/14.6 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 10.8/14.6 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 11.1/14.6 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.4/14.6 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 11.9/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 12.2/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 12.3/14.6 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 12.6/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 12.8/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 13.1/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 13.3/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.9/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 14.1/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.4/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 14.6/14.6 MB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "Collecting pl-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_sm-3.8.0/pl_core_news_sm-3.8.0-py3-none-any.whl (20.2 MB)\n",
      "     ---------------------------------------- 0.0/20.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/20.2 MB 2.0 MB/s eta 0:00:11\n",
      "     ---------------------------------------- 0.2/20.2 MB 1.7 MB/s eta 0:00:12\n",
      "      --------------------------------------- 0.4/20.2 MB 2.6 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.7/20.2 MB 3.2 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.8/20.2 MB 3.2 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 1.0/20.2 MB 3.3 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 1.0/20.2 MB 3.3 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 1.0/20.2 MB 2.5 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 1.0/20.2 MB 2.5 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 1.2/20.2 MB 2.2 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 1.2/20.2 MB 2.1 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 2.3/20.2 MB 3.6 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 2.5/20.2 MB 3.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 2.8/20.2 MB 3.8 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 2.8/20.2 MB 3.6 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 3.4/20.2 MB 4.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.6/20.2 MB 4.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.8/20.2 MB 4.2 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 4.2/20.2 MB 4.3 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 4.5/20.2 MB 4.3 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 5.0/20.2 MB 4.4 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 5.2/20.2 MB 4.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 5.4/20.2 MB 4.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 5.8/20.2 MB 4.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 6.0/20.2 MB 4.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 6.3/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 6.6/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 7.0/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 7.2/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 7.5/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 7.7/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 7.9/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 8.3/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 8.6/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 8.9/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 9.2/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 9.4/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.7/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.9/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 10.2/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 10.4/20.2 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 10.6/20.2 MB 5.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 10.9/20.2 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 11.2/20.2 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 11.4/20.2 MB 5.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 11.7/20.2 MB 5.7 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 12.0/20.2 MB 5.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 12.2/20.2 MB 5.5 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 12.6/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 12.8/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 13.2/20.2 MB 5.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 13.4/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.7/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 14.0/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 14.2/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 14.5/20.2 MB 5.3 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 14.9/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 15.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 15.5/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 15.9/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 16.0/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 16.3/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 16.6/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 16.9/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 17.0/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 17.2/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 17.4/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 17.7/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 18.1/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 18.3/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 18.6/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.8/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 19.1/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 19.4/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 19.7/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.1/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 20.2/20.2 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pl-core-news-sm\n",
      "Successfully installed pl-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pl_core_news_sm')\n",
      "Collecting fi-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fi_core_news_sm-3.8.0/fi_core_news_sm-3.8.0-py3-none-any.whl (14.3 MB)\n",
      "     ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/14.3 MB 2.4 MB/s eta 0:00:06\n",
      "      --------------------------------------- 0.4/14.3 MB 3.7 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.5/14.3 MB 3.0 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.7/14.3 MB 3.3 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.7/14.3 MB 3.1 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 1.0/14.3 MB 3.4 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.4/14.3 MB 4.1 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.7/14.3 MB 4.2 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 2.0/14.3 MB 4.6 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/14.3 MB 4.3 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.8/14.3 MB 4.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 3.1/14.3 MB 4.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.4/14.3 MB 5.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.9/14.3 MB 5.1 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 4.2/14.3 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.5/14.3 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.8/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 5.1/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.4/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.7/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 6.0/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 6.3/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.5/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.7/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 7.1/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 7.4/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.6/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.9/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.3/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.6/14.3 MB 5.6 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.0/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 9.1/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 9.5/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 9.7/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 9.7/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 10.3/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 10.5/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 10.5/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 10.9/14.3 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.3/14.3 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 11.6/14.3 MB 5.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.9/14.3 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 12.2/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 12.6/14.3 MB 5.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 12.8/14.3 MB 5.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 13.1/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.3/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.6/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 13.8/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.1/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 14.3/14.3 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: fi-core-news-sm\n",
      "Successfully installed fi-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fi_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download pl_core_news_sm\n",
    "!python -m spacy download fi_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61524bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://minio.lab.sspcloud.fr/nguibe/NLP/multi_eurlex_reduced.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab2041",
   "metadata": {},
   "source": [
    "# 1 - Original model through token analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed48645",
   "metadata": {},
   "source": [
    "## Cleaning and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee35895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy models for each language\n",
    "spacy_models = {\n",
    "    \"en\": spacy.load(\"en_core_web_sm\"),\n",
    "    \"fr\": spacy.load(\"fr_core_news_sm\"),\n",
    "    \"de\": spacy.load(\"de_core_news_sm\"),\n",
    "    \"pl\": spacy.load(\"pl_core_news_sm\"),\n",
    "    \"fi\": spacy.load(\"fi_core_news_sm\")\n",
    "}\n",
    "\n",
    "# List of languages you care about\n",
    "languages = [\"en\", \"fr\", \"de\", \"pl\", \"fi\"]\n",
    "\n",
    "# Function to clean and lemmatize text\n",
    "def clean_and_lemmatize(text, lang_code, remove_stopwords=True):\n",
    "    if lang_code not in spacy_models:\n",
    "        return None\n",
    "    \n",
    "    nlp = spacy_models[lang_code]\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = [\n",
    "        token.lemma_.lower() for token in doc\n",
    "        if not token.is_punct and not token.is_space and (not token.is_stop if remove_stopwords else True)\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply cleaning/lemmatization across the dataframe\n",
    "def process_dataframe(df, languages):\n",
    "    lemmatized_texts = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text_dict = row[\"text\"]  # {lang: text}\n",
    "        labels = row[\"level_1_labels\"]\n",
    "\n",
    "        for lang in languages:\n",
    "            if isinstance(text_dict, dict) and lang in text_dict:\n",
    "                raw_text = text_dict[lang]\n",
    "                lemmatized = clean_and_lemmatize(raw_text, lang)\n",
    "                if lemmatized:\n",
    "                    lemmatized_texts.append({\n",
    "                        \"lang\": lang,\n",
    "                        \"text_lemmatized\": lemmatized,\n",
    "                        \"labels\": labels\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(lemmatized_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ee9408",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "realloc of size 731906048 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/guibe/OneDrive/Documents/ENSAE/3A/S2/NLP/projet/multi_eurlex_reduced.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pandas\\io\\parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    268\u001b[0m     path,\n\u001b[0;32m    269\u001b[0m     filesystem,\n\u001b[0;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    277\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    278\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1843\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[0;32m   1831\u001b[0m     \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   1832\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[0;32m   1833\u001b[0m         source, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[0;32m   1834\u001b[0m         memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         page_checksum_verification\u001b[38;5;241m=\u001b[39mpage_checksum_verification,\n\u001b[0;32m   1841\u001b[0m     )\n\u001b[1;32m-> 1843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mread(columns\u001b[38;5;241m=\u001b[39mcolumns, use_threads\u001b[38;5;241m=\u001b[39muse_threads,\n\u001b[0;32m   1844\u001b[0m                     use_pandas_metadata\u001b[38;5;241m=\u001b[39muse_pandas_metadata)\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1485\u001b[0m, in \u001b[0;36mParquetDataset.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1478\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[0;32m   1479\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   1480\u001b[0m         ]\n\u001b[0;32m   1481\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1482\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[0;32m   1483\u001b[0m         )\n\u001b[1;32m-> 1485\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset\u001b[38;5;241m.\u001b[39mto_table(\n\u001b[0;32m   1486\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_expression,\n\u001b[0;32m   1487\u001b[0m     use_threads\u001b[38;5;241m=\u001b[39muse_threads\n\u001b[0;32m   1488\u001b[0m )\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pyarrow\\_dataset.pyx:562\u001b[0m, in \u001b[0;36mpyarrow._dataset.Dataset.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pyarrow\\_dataset.pyx:3841\u001b[0m, in \u001b[0;36mpyarrow._dataset.Scanner.to_table\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pyarrow\\error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\vscode\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: realloc of size 731906048 failed"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('C:/Users/guibe/OneDrive/Documents/ENSAE/3A/S2/NLP/projet/multi_eurlex_reduced.parquet')\n",
    "df = df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c50f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"multi_eurlex\", 'all_languages',split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34573e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"multi_eurlex\", 'all_languages',split=\"train[:1%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ccc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f566a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = list(islice(dataset, 5))  # Adjust number as needed\n",
    "df = pd.DataFrame(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b061b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 20, 7, 3, 0]\n",
       "1             [2, 17]\n",
       "2          [3, 19, 6]\n",
       "3     [12, 17, 19, 6]\n",
       "4       [18, 3, 4, 1]\n",
       "Name: labels, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "processed_df = process_dataframe(df, languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later use\n",
    "processed_df.to_parquet(\"data/processed_legal_texts.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22d80a",
   "metadata": {},
   "source": [
    "## Token - Label co-occurence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed lemmatized texts\n",
    "df = pd.read_parquet(\"data/processed_legal_texts.parquet\")\n",
    "\n",
    "# Build token-label co-occurrence mapping\n",
    "token_label_counts = defaultdict(Counter)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    tokens = row[\"text_lemmatized\"].split()\n",
    "    labels = row[\"labels\"]\n",
    "    \n",
    "# Count each token against all its labels\n",
    "    for token in set(tokens):\n",
    "        for label in labels:\n",
    "            token_label_counts[token][label] += 1\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "top_tokens = sorted(token_label_counts.items(), key=lambda x: sum(x[1].values()), reverse=True)[:100]\n",
    "\n",
    "rows = []\n",
    "for token, label_counter in top_tokens:\n",
    "    for label, count in label_counter.items():\n",
    "        rows.append({\"token\": token, \"label\": label, \"count\": count})\n",
    "\n",
    "df_token_label = pd.DataFrame(rows)\n",
    "df_token_label.to_csv(\"output/token_label_cooccurrence.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize token-label counts for one label\n",
    "def plot_top_tokens_for_label(label, top_n=10):\n",
    "    label_filtered = df_token_label[df_token_label[\"label\"] == label]\n",
    "    top = label_filtered.sort_values(\"count\", ascending=False).head(top_n)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(top[\"token\"], top[\"count\"])\n",
    "    plt.title(f\"Top {top_n} tokens for label {label}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac42346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: plot_top_tokens_for_label(\"0806\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd659b22",
   "metadata": {},
   "source": [
    "## Token distribution accross languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same preprocessed file\n",
    "df = pd.read_parquet(\"data/processed_legal_texts.parquet\")\n",
    "\n",
    "# Count token frequencies by language\n",
    "lang_token_freq = defaultdict(Counter)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    lang = row[\"lang\"]\n",
    "    tokens = row[\"text_lemmatized\"].split()\n",
    "    lang_token_freq[lang].update(tokens)\n",
    "\n",
    "# Create a DataFrame with token frequencies across languages\n",
    "def get_freq_df(top_tokens=None, min_freq=50):\n",
    "    all_tokens = set()\n",
    "    if top_tokens:\n",
    "        all_tokens = set(top_tokens)\n",
    "    else:\n",
    "        # Get common tokens across languages\n",
    "        for lang, counter in lang_token_freq.items():\n",
    "            common = {token for token, freq in counter.items() if freq > min_freq}\n",
    "            all_tokens |= common\n",
    "\n",
    "    data = []\n",
    "    for token in all_tokens:\n",
    "        row = {\"token\": token}\n",
    "        for lang in lang_token_freq:\n",
    "            row[lang] = lang_token_freq[lang][token]\n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of selected tokens\n",
    "def plot_token_distribution(tokens):\n",
    "    df_freq = get_freq_df(tokens)\n",
    "    df_freq.set_index(\"token\").T.plot(kind='bar', figsize=(10, 5))\n",
    "    plt.title(\"Token frequency across languages\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Language\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4739480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# plot_token_distribution([\"regulation\", \"union\", \"market\", \"recht\", \"union\", \"protection\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13973a07",
   "metadata": {},
   "source": [
    "What You Can Explore With These:\n",
    "Token–Label Co-occurrence:\n",
    "•\tFind tokens that strongly signal a specific legal topic (label).\n",
    "•\tDetect domain-specific terms frequently co-occurring with multi-label groups.\n",
    "Cross-Language Token Comparison:\n",
    "•\tDiscover shared Latin-root legal vocabulary (e.g., regulation, directive, protection).\n",
    "•\tIdentify language-specific phrasing or underrepresentation of concepts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdba69b",
   "metadata": {},
   "source": [
    "# 2 - Other strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b707c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 09:05:17.217370: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-03 09:05:17.223079: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 09:05:17.233750: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-03 09:05:17.416622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746263117.537261  188376 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746263117.623693  188376 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746263117.821885  188376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746263117.821944  188376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746263117.821949  188376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746263117.821951  188376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 09:05:17.915148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.label_embedding import run_label_embedding_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cad947",
   "metadata": {},
   "source": [
    "## Prompt based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c305c57",
   "metadata": {},
   "source": [
    "## label based embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c34371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for lang in [\"en\", \"fr\", \"de\", \"pl\", \"fi\"]:\n",
    "    res = run_label_embedding_classification(df, top_k=5, batch_size=32, eval_lang=lang)\n",
    "    all_results.append(res)\n",
    "\n",
    "final_df = pd.DataFrame(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
