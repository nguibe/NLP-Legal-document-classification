{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f94e9b0",
   "metadata": {},
   "source": [
    "# Legal document classification in zero-shot cross lingual transfer setting\n",
    "\n",
    "# Part III: Performance improvement and pattern analysis\n",
    "\n",
    "Date: May 2025\n",
    "\n",
    "Project of course: Natural Language Processing - ENSAE 3A S2\n",
    "\n",
    "Author: Noémie Guibé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed2c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11157383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "      --------------------------------------- 0.2/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.3/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.6/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.7/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.7/12.8 MB 2.4 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.9/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.2/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.0/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.1/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.4/12.8 MB 3.4 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.7/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.2/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.9/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.1/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.3/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.6/12.8 MB 3.9 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.9/12.8 MB 4.0 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.8/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.4/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.7/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.6/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.6/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 4.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 4.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.1 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/16.3 MB 991.0 kB/s eta 0:00:17\n",
      "     ---------------------------------------- 0.1/16.3 MB 1.1 MB/s eta 0:00:15\n",
      "      --------------------------------------- 0.2/16.3 MB 1.7 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.5/16.3 MB 2.2 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.6/16.3 MB 2.4 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 0.8/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/16.3 MB 1.8 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 0.8/16.3 MB 1.8 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.3/16.3 MB 2.3 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.7/16.3 MB 2.6 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.9/16.3 MB 2.8 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 2.1/16.3 MB 3.0 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 2.2/16.3 MB 3.0 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.5/16.3 MB 3.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.1/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.3/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.6/16.3 MB 3.7 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.9/16.3 MB 3.8 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 4.0/16.3 MB 3.8 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 4.0/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 4.1/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 4.4/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 4.6/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 4.8/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.9/16.3 MB 3.5 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 5.2/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 5.4/16.3 MB 3.6 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 5.6/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.7/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.9/16.3 MB 3.5 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 6.0/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 6.4/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 6.7/16.3 MB 3.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 7.0/16.3 MB 3.7 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 7.3/16.3 MB 3.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 7.6/16.3 MB 3.8 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 7.9/16.3 MB 3.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 8.2/16.3 MB 3.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 8.4/16.3 MB 3.9 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 8.8/16.3 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 9.1/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 9.3/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 9.5/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 9.7/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 10.0/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 10.3/16.3 MB 4.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 10.4/16.3 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 10.7/16.3 MB 4.2 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 11.0/16.3 MB 4.3 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 11.2/16.3 MB 4.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 11.5/16.3 MB 4.5 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 11.7/16.3 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 12.1/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 12.5/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 12.6/16.3 MB 4.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 13.0/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 13.3/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 13.6/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 13.9/16.3 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 14.2/16.3 MB 4.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 14.5/16.3 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 14.8/16.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 15.1/16.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 15.4/16.3 MB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 15.7/16.3 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.0/16.3 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 16.3/16.3 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n",
      "Collecting de-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "     ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/14.6 MB 3.2 MB/s eta 0:00:05\n",
      "     ---------------------------------------- 0.2/14.6 MB 2.0 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.3/14.6 MB 1.7 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.4/14.6 MB 1.9 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.5/14.6 MB 1.8 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.6/14.6 MB 1.8 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.7/14.6 MB 1.9 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 0.8/14.6 MB 2.1 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 1.0/14.6 MB 2.2 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.1/14.6 MB 2.3 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.3/14.6 MB 2.4 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.6/14.6 MB 2.0 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 2.1/14.6 MB 2.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.3/14.6 MB 2.5 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.5/14.6 MB 2.7 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.9/14.6 MB 2.8 MB/s eta 0:00:05\n",
      "     -------- ------------------------------- 3.1/14.6 MB 2.9 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 3.2/14.6 MB 2.9 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 3.6/14.6 MB 3.0 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 3.9/14.6 MB 3.1 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 4.2/14.6 MB 3.2 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 4.6/14.6 MB 3.3 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.8/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 5.0/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 5.3/14.6 MB 3.4 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.7/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.9/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 6.0/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 6.4/14.6 MB 3.7 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 6.4/14.6 MB 3.7 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 6.5/14.6 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.8/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 7.0/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 7.3/14.6 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 7.5/14.6 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.8/14.6 MB 3.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 8.0/14.6 MB 3.7 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 8.3/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.5/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.7/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 8.9/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.2/14.6 MB 3.8 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.4/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 9.6/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 9.8/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 10.1/14.6 MB 3.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 10.4/14.6 MB 4.0 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 10.7/14.6 MB 4.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 10.8/14.6 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 11.1/14.6 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.4/14.6 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 11.9/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 12.2/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 12.3/14.6 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 12.6/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 12.8/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 13.1/14.6 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 13.3/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.9/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 14.1/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.4/14.6 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.6/14.6 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 14.6/14.6 MB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "Collecting pl-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_sm-3.8.0/pl_core_news_sm-3.8.0-py3-none-any.whl (20.2 MB)\n",
      "     ---------------------------------------- 0.0/20.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/20.2 MB 2.0 MB/s eta 0:00:11\n",
      "     ---------------------------------------- 0.2/20.2 MB 1.7 MB/s eta 0:00:12\n",
      "      --------------------------------------- 0.4/20.2 MB 2.6 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 0.7/20.2 MB 3.2 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.8/20.2 MB 3.2 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 1.0/20.2 MB 3.3 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 1.0/20.2 MB 3.3 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 1.0/20.2 MB 2.5 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 1.0/20.2 MB 2.5 MB/s eta 0:00:08\n",
      "     -- ------------------------------------- 1.2/20.2 MB 2.2 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 1.2/20.2 MB 2.1 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 2.3/20.2 MB 3.6 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 2.5/20.2 MB 3.7 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 2.8/20.2 MB 3.8 MB/s eta 0:00:05\n",
      "     ----- ---------------------------------- 2.8/20.2 MB 3.6 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 3.4/20.2 MB 4.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.6/20.2 MB 4.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 3.8/20.2 MB 4.2 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 4.2/20.2 MB 4.3 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 4.5/20.2 MB 4.3 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 5.0/20.2 MB 4.4 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 5.2/20.2 MB 4.5 MB/s eta 0:00:04\n",
      "     ---------- ----------------------------- 5.4/20.2 MB 4.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 5.8/20.2 MB 4.5 MB/s eta 0:00:04\n",
      "     ----------- ---------------------------- 6.0/20.2 MB 4.6 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 6.3/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 6.6/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 7.0/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 7.2/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 7.5/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 7.7/20.2 MB 4.7 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 7.9/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 8.3/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 8.6/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 8.9/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 9.2/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 9.4/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.7/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 9.9/20.2 MB 4.8 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 10.2/20.2 MB 4.9 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 10.4/20.2 MB 5.0 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 10.6/20.2 MB 5.0 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 10.9/20.2 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 11.2/20.2 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 11.4/20.2 MB 5.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 11.7/20.2 MB 5.7 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 12.0/20.2 MB 5.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 12.2/20.2 MB 5.5 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 12.6/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 12.8/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 13.2/20.2 MB 5.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 13.4/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 13.7/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 14.0/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 14.2/20.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 14.5/20.2 MB 5.3 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 14.9/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 15.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 15.5/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 15.9/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 16.0/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 16.3/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 16.6/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 16.9/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 17.0/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 17.2/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 17.4/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 17.7/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 18.1/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 18.3/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 18.6/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 18.8/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 19.1/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 19.4/20.2 MB 5.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 19.7/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.1/20.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.2/20.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 20.2/20.2 MB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pl-core-news-sm\n",
      "Successfully installed pl-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pl_core_news_sm')\n",
      "Collecting fi-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fi_core_news_sm-3.8.0/fi_core_news_sm-3.8.0-py3-none-any.whl (14.3 MB)\n",
      "     ---------------------------------------- 0.0/14.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/14.3 MB 2.4 MB/s eta 0:00:06\n",
      "      --------------------------------------- 0.4/14.3 MB 3.7 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.5/14.3 MB 3.0 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.7/14.3 MB 3.3 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 0.7/14.3 MB 3.1 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 1.0/14.3 MB 3.4 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.4/14.3 MB 4.1 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.7/14.3 MB 4.2 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 2.0/14.3 MB 4.6 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/14.3 MB 4.3 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.8/14.3 MB 4.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 3.1/14.3 MB 4.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.4/14.3 MB 5.1 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.9/14.3 MB 5.1 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 4.2/14.3 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.5/14.3 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.8/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 5.1/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.4/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.7/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 6.0/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 6.3/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.5/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.7/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 7.1/14.3 MB 5.4 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 7.4/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.6/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.9/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.3/14.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 8.6/14.3 MB 5.6 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 9.0/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 9.1/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 9.5/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 9.7/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 9.7/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 10.3/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 10.5/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 10.5/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 10.9/14.3 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 11.3/14.3 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 11.6/14.3 MB 5.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 11.9/14.3 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 12.2/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 12.6/14.3 MB 5.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 12.8/14.3 MB 5.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 13.1/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.3/14.3 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 13.6/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 13.8/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.1/14.3 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  14.3/14.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 14.3/14.3 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: fi-core-news-sm\n",
      "Successfully installed fi-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fi_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download pl_core_news_sm\n",
    "!python -m spacy download fi_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61524bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://minio.lab.sspcloud.fr/nguibe/NLP/multi_eurlex_reduced.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab2041",
   "metadata": {},
   "source": [
    "# 1 - Original model through token analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8258577",
   "metadata": {},
   "source": [
    "This section was intended to explore token patterns accross languages in the specific legal field.\n",
    "\n",
    "Due to time constraints, this analysis was not completed. However, the following code sketch could be used to pursue this direction later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed48645",
   "metadata": {},
   "source": [
    "## Cleaning and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee35895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy models for each language\n",
    "spacy_models = {\n",
    "    \"en\": spacy.load(\"en_core_web_sm\"),\n",
    "    \"fr\": spacy.load(\"fr_core_news_sm\"),\n",
    "    \"de\": spacy.load(\"de_core_news_sm\"),\n",
    "    \"pl\": spacy.load(\"pl_core_news_sm\"),\n",
    "    \"fi\": spacy.load(\"fi_core_news_sm\")\n",
    "}\n",
    "\n",
    "# List of languages you care about\n",
    "languages = [\"en\", \"fr\", \"de\", \"pl\", \"fi\"]\n",
    "\n",
    "# Function to clean and lemmatize text\n",
    "def clean_and_lemmatize(text, lang_code, remove_stopwords=True):\n",
    "    if lang_code not in spacy_models:\n",
    "        return None\n",
    "    \n",
    "    nlp = spacy_models[lang_code]\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = [\n",
    "        token.lemma_.lower() for token in doc\n",
    "        if not token.is_punct and not token.is_space and (not token.is_stop if remove_stopwords else True)\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply cleaning/lemmatization across the dataframe\n",
    "def process_dataframe(df, languages):\n",
    "    lemmatized_texts = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text_dict = row[\"text\"]  # {lang: text}\n",
    "        labels = row[\"level_1_labels\"]\n",
    "\n",
    "        for lang in languages:\n",
    "            if isinstance(text_dict, dict) and lang in text_dict:\n",
    "                raw_text = text_dict[lang]\n",
    "                lemmatized = clean_and_lemmatize(raw_text, lang)\n",
    "                if lemmatized:\n",
    "                    lemmatized_texts.append({\n",
    "                        \"lang\": lang,\n",
    "                        \"text_lemmatized\": lemmatized,\n",
    "                        \"labels\": labels\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(lemmatized_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "processed_df = process_dataframe(df, languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later use\n",
    "processed_df.to_parquet(\"data/processed_legal_texts.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d22d80a",
   "metadata": {},
   "source": [
    "## Token - Label co-occurence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed lemmatized texts\n",
    "df = pd.read_parquet(\"data/processed_legal_texts.parquet\")\n",
    "\n",
    "# Build token-label co-occurrence mapping\n",
    "token_label_counts = defaultdict(Counter)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    tokens = row[\"text_lemmatized\"].split()\n",
    "    labels = row[\"labels\"]\n",
    "    \n",
    "# Count each token against all its labels\n",
    "    for token in set(tokens):\n",
    "        for label in labels:\n",
    "            token_label_counts[token][label] += 1\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "top_tokens = sorted(token_label_counts.items(), key=lambda x: sum(x[1].values()), reverse=True)[:100]\n",
    "\n",
    "rows = []\n",
    "for token, label_counter in top_tokens:\n",
    "    for label, count in label_counter.items():\n",
    "        rows.append({\"token\": token, \"label\": label, \"count\": count})\n",
    "\n",
    "df_token_label = pd.DataFrame(rows)\n",
    "df_token_label.to_csv(\"output/token_label_cooccurrence.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize token-label counts for one label\n",
    "def plot_top_tokens_for_label(label, top_n=10):\n",
    "    label_filtered = df_token_label[df_token_label[\"label\"] == label]\n",
    "    top = label_filtered.sort_values(\"count\", ascending=False).head(top_n)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(top[\"token\"], top[\"count\"])\n",
    "    plt.title(f\"Top {top_n} tokens for label {label}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac42346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: plot_top_tokens_for_label(\"xx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd659b22",
   "metadata": {},
   "source": [
    "## Token distribution accross languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same preprocessed file\n",
    "df = pd.read_parquet(\"data/processed_legal_texts.parquet\")\n",
    "\n",
    "# Count token frequencies by language\n",
    "lang_token_freq = defaultdict(Counter)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    lang = row[\"lang\"]\n",
    "    tokens = row[\"text_lemmatized\"].split()\n",
    "    lang_token_freq[lang].update(tokens)\n",
    "\n",
    "# Create a DataFrame with token frequencies across languages\n",
    "def get_freq_df(top_tokens=None, min_freq=50):\n",
    "    all_tokens = set()\n",
    "    if top_tokens:\n",
    "        all_tokens = set(top_tokens)\n",
    "    else:\n",
    "        # Get common tokens across languages\n",
    "        for lang, counter in lang_token_freq.items():\n",
    "            common = {token for token, freq in counter.items() if freq > min_freq}\n",
    "            all_tokens |= common\n",
    "\n",
    "    data = []\n",
    "    for token in all_tokens:\n",
    "        row = {\"token\": token}\n",
    "        for lang in lang_token_freq:\n",
    "            row[lang] = lang_token_freq[lang][token]\n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of selected tokens\n",
    "def plot_token_distribution(tokens):\n",
    "    df_freq = get_freq_df(tokens)\n",
    "    df_freq.set_index(\"token\").T.plot(kind='bar', figsize=(10, 5))\n",
    "    plt.title(\"Token frequency across languages\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Language\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4739480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot_token_distribution([\"regulation\", \"union\", \"market\", \"recht\", \"union\", \"protection\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdba69b",
   "metadata": {},
   "source": [
    "# 2 - Other strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b707c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 13:24:01.425239: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 13:24:01.427161: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-04 13:24:01.432311: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-04 13:24:01.445320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746365041.466352  264702 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746365041.472470  264702 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746365041.489545  264702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746365041.489564  264702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746365041.489566  264702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746365041.489567  264702 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-04 13:24:01.495590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src import label_embedding, prompt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cad947",
   "metadata": {},
   "source": [
    "## Prompt based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test set size: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:05<00:00, 922.15 examples/s] \n",
      "Map: 100%|██████████| 987/987 [00:02<00:00, 469.74 examples/s]\n",
      "Map: 100%|██████████| 1024/1024 [00:01<00:00, 723.11 examples/s]\n",
      "Map: 100%|██████████| 1003/1003 [00:02<00:00, 494.85 examples/s]\n",
      "Map: 100%|██████████| 1014/1014 [00:02<00:00, 453.33 examples/s]\n",
      "Map: 100%|██████████| 972/972 [00:01<00:00, 488.07 examples/s]\n",
      "All PyTorch model weights were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFXLMRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "results =prompt_model.run_prompt_classification(\n",
    "    df=df,\n",
    "    train_size=5000,\n",
    "    test_size=5000,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "    prompt_type=\"guided\",  # or \"generic\"\n",
    "    # freeze_layers=6        # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb185280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c305c57",
   "metadata": {},
   "source": [
    "## label based embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c34371d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n",
      "100%|██████████| 157/157 [45:19<00:00, 17.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RESULTS]\n",
      "Language: en\n",
      "Top-5 Micro F1: 0.2631\n",
      "Top-5 Macro F1: 0.1001\n",
      "Top-5 LRAP:     0.2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n",
      "100%|██████████| 157/157 [35:48<00:00, 13.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RESULTS]\n",
      "Language: fr\n",
      "Top-5 Micro F1: 0.2649\n",
      "Top-5 Macro F1: 0.0941\n",
      "Top-5 LRAP:     0.2174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n",
      "100%|██████████| 157/157 [27:45<00:00, 10.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RESULTS]\n",
      "Language: de\n",
      "Top-5 Micro F1: 0.2637\n",
      "Top-5 Macro F1: 0.0923\n",
      "Top-5 LRAP:     0.2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n",
      "100%|██████████| 157/157 [27:55<00:00, 10.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RESULTS]\n",
      "Language: pl\n",
      "Top-5 Micro F1: 0.2634\n",
      "Top-5 Macro F1: 0.0907\n",
      "Top-5 LRAP:     0.2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n",
      "100%|██████████| 157/157 [27:22<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RESULTS]\n",
      "Language: fi\n",
      "Top-5 Micro F1: 0.2654\n",
      "Top-5 Macro F1: 0.0938\n",
      "Top-5 LRAP:     0.2176\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for lang in [\"en\", \"fr\", \"de\", \"pl\", \"fi\"]:\n",
    "    res = label_embedding.run_label_embedding_classification(df, top_k=5, batch_size=32, eval_lang=lang)\n",
    "    all_results.append(res)\n",
    "\n",
    "final_df = pd.DataFrame(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
